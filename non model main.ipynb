{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from utils import *\n",
    "\n",
    "from dynamicgem.embedding.dynAERNN  import DynAERNN \n",
    "import dgl  \n",
    "import scipy as sp\n",
    "import scipy.linalg as linalg\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "from scipy import stats \n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "from itertools import permutations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py): started\n",
      "  Building wheel for pytorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Installing collected packages: pytorch\n",
      "    Running setup.py install for pytorch: started\n",
      "    Running setup.py install for pytorch: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-utafe9io\\\\pytorch_3e9946fc83bc426e8dbfa805aa855765\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-utafe9io\\\\pytorch_3e9946fc83bc426e8dbfa805aa855765\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\conno\\AppData\\Local\\Temp\\pip-wheel-bv_g61pl'\n",
      "       cwd: C:\\Users\\conno\\AppData\\Local\\Temp\\pip-install-utafe9io\\pytorch_3e9946fc83bc426e8dbfa805aa855765\\\n",
      "  Complete output (5 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\conno\\AppData\\Local\\Temp\\pip-install-utafe9io\\pytorch_3e9946fc83bc426e8dbfa805aa855765\\setup.py\", line 15, in <module>\n",
      "      raise Exception(message)\n",
      "  Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-utafe9io\\\\pytorch_3e9946fc83bc426e8dbfa805aa855765\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-utafe9io\\\\pytorch_3e9946fc83bc426e8dbfa805aa855765\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\conno\\AppData\\Local\\Temp\\pip-record-bhtmwi1r\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\Include\\pytorch'\n",
      "         cwd: C:\\Users\\conno\\AppData\\Local\\Temp\\pip-install-utafe9io\\pytorch_3e9946fc83bc426e8dbfa805aa855765\\\n",
      "    Complete output (5 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\conno\\AppData\\Local\\Temp\\pip-install-utafe9io\\pytorch_3e9946fc83bc426e8dbfa805aa855765\\setup.py\", line 11, in <module>\n",
      "        raise Exception(message)\n",
      "    Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-utafe9io\\\\pytorch_3e9946fc83bc426e8dbfa805aa855765\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-utafe9io\\\\pytorch_3e9946fc83bc426e8dbfa805aa855765\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\conno\\AppData\\Local\\Temp\\pip-record-bhtmwi1r\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\Include\\pytorch' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(id: str): #DBLP3, DBLP5, Brain, Reddit, DBLPE\n",
    "    dataset_dict=dict()\n",
    "    dataset_dict[\"DBLP3\"]=\"Datasets/DBLP3.npz\"\n",
    "    dataset_dict[\"DBLP5\"]=\"Datasets/DBLP5.npz\"\n",
    "    dataset_dict[\"Brain\"]=\"Datasets/Brain.npz\"\n",
    "    dataset_dict[\"Reddit\"]=\"Datasets/reddit.npz\"\n",
    "    dataset_dict[\"DBLPE\"]=\"Datasets/DBLPE.npz\"\n",
    "\n",
    "    dataset = np.load(dataset_dict[id])\n",
    "    adjs = dataset[\"adjs\"] #(time, node, node)\n",
    "\n",
    "    #Remove nodes with no connections at any timestep\n",
    "    temporal_sum = np.add.reduce(adjs, axis=0, keepdims=False)\n",
    "    row_sum = np.add.reduce(temporal_sum, axis=0, keepdims=False)\n",
    "    non_zero_indices = np.flatnonzero(row_sum)\n",
    "    adjs = adjs[:,non_zero_indices,:]\n",
    "    adjs = adjs[:,:,non_zero_indices]\n",
    "\n",
    "    #DBLPE is a dynamic featureless graph\n",
    "    if id==\"DBLPE\":\n",
    "        labels = dataset[\"labels\"] #(nodes, time, class)\n",
    "\n",
    "        # labels = np.argmax(labels,axis=2)\n",
    "        labels=labels[non_zero_indices]\n",
    "        feats=np.zeros([adjs.shape[1], adjs.shape[0], adjs.shape[2]])\n",
    "\n",
    "        for i in range(feats.shape[1]):\n",
    "            feats[:,i,:]=np.eye(feats.shape[0])\n",
    "      \n",
    "    #All others are static feature-full graphs\n",
    "    else:\n",
    "        labels = dataset[\"labels\"] #(nodes, class)\n",
    "        feats = dataset[\"attmats\"] #(node, time, feat)\n",
    "\n",
    "        # labels = np.argmax(labels, axis=1)\n",
    "        labels = labels[non_zero_indices]\n",
    "        feats = feats[non_zero_indices]\n",
    "\n",
    "    #Other important variables\n",
    "    n_nodes = adjs.shape[1]\n",
    "    n_timesteps = adjs.shape[0]\n",
    "    n_class = int(labels.shape[1])\n",
    "    n_feat = feats.shape[2]\n",
    "\n",
    "    #Train Val Test split\n",
    "    nodes_id = list(range(n_nodes))\n",
    "    random.shuffle(nodes_id)\n",
    "    idx_train = nodes_id[:(7*n_nodes)//10]\n",
    "    idx_train = [True if i in idx_train else False for i in list(range(n_nodes))]\n",
    "    idx_val = nodes_id[(7*n_nodes)//10: (9*n_nodes)//10]\n",
    "    idx_val = [True if i in idx_val else False for i in list(range(n_nodes))]\n",
    "    idx_test = nodes_id[(9*n_nodes)//10: n_nodes]\n",
    "    idx_test = [True if i in idx_test else False for i in list(range(n_nodes))]\n",
    "\n",
    "    return STG_Dataset(np.array(adjs),\n",
    "                        np.array(adjs),\n",
    "                        np.array(feats), \n",
    "                        np.array(feats), \n",
    "                        np.array(labels), \n",
    "                        np.array(labels), \n",
    "                        n_nodes, n_timesteps, n_class, n_feat, \n",
    "                        np.array(idx_train),\n",
    "                        np.array(idx_val),\n",
    "                        np.array(idx_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynaernn(data):\n",
    "    length=data.n_timestamps\n",
    "    lookup=length-2\n",
    "\n",
    "    dim_emb  = data.n_class\n",
    "          \n",
    "    tf.device('/gpu:0')\n",
    "\n",
    "    embedding = DynAERNN(d   = dim_emb,\n",
    "        beta           = 5,\n",
    "        n_prev_graphs  = lookup,\n",
    "        nu1            = 1e-6,\n",
    "        nu2            = 1e-6,\n",
    "        n_aeunits      = [50, 30],\n",
    "        n_lstmunits    = [50,dim_emb],\n",
    "        rho            = 0.3,\n",
    "        n_iter         = 2,\n",
    "        xeta           = 1e-3,\n",
    "        n_batch        = 10,\n",
    "        modelfile      = ['./intermediate/enc_model_dynAERNN.json', \n",
    "                            './intermediate/dec_model_dynAERNN.json'],\n",
    "        weightfile     = ['./intermediate/enc_weights_dynAERNN.hdf5', \n",
    "                            './intermediate/dec_weights_dynAERNN.hdf5'],\n",
    "        savefilesuffix = \"testing\")\n",
    "    embs = []\n",
    "\n",
    "    graphs     = [nx.Graph(data.adjs[l,:,:]) for l in range(length)]\n",
    "    for temp_var in range(lookup, length):\n",
    "                    emb, _ = embedding.learn_embeddings(graphs[:temp_var])\n",
    "                    embs.append(emb)\n",
    "    centroid=kmeans(embs[-1],data.n_class)[0] #change kSigvec from complex64 to float\n",
    "    result=vq(embs[-1],centroid)[0]\n",
    "\n",
    "\n",
    "\n",
    "    perm = permutations(range(data.n_class)) \n",
    "    one_hot_result=one_hot(result,data.n_class)\n",
    "    acc_test=0\n",
    "    f1_test=0\n",
    "    auc_test=0\n",
    "    count=0\n",
    "    for i in perm: \n",
    "        count+=1\n",
    "        one_hot_i=one_hot(np.array(i))\n",
    "        perm_result=np.matmul(one_hot_result,one_hot_i)\n",
    "        labels = np.argmax(data.labels,axis=1)\n",
    "        pred_labels=np.argmax(perm_result,axis=1)\n",
    "        acc_test = max(metrics.accuracy_score(labels,pred_labels),acc_test)\n",
    "        f1_test=max(metrics.f1_score(labels, pred_labels,average='weighted'),f1_test)\n",
    "        auc_test=max(metrics.roc_auc_score(one_hot(labels), perm_result,multi_class='ovr',average='weighted'),auc_test)\n",
    "        if count%10000==0:\n",
    "            print(count)\n",
    "            print(acc_test,f1_test,auc_test)   \n",
    "    print(str(acc_test)+'\\t'+str(f1_test)+'\\t'+str(auc_test))  \n",
    "    try:\n",
    "        spec_norm=getKlargestSigVec(adj-Probability_matrix,2)[0]\n",
    "    except:\n",
    "        spec_norm=[]\n",
    "    return 0,acc_test,spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral(data):\n",
    "    adj = np.add.reduce(data.adjs_timestep, axis=0, keepdims=False, dtype=np.float32)\n",
    "\n",
    "    #normalize the adj matrix\n",
    "    adj += np.eye(adj.shape[0], dtype=np.float32)\n",
    "    d = np.add.reduce(adj, axis=1)\n",
    "    normalizing_matrix = np.zeros((adj.shape[0], adj.shape[0]))\n",
    "    normalizing_matrix[range(len(normalizing_matrix)), range(len(normalizing_matrix))] = d**(-0.5)\n",
    "    adj = np.matmul(normalizing_matrix,adj)\n",
    "    adj=np.matmul(np.matmul(normalizing_matrix,adj), normalizing_matrix)\n",
    "\n",
    "    Lbar=np.array(adj)  #no normalizaton\n",
    "    top_k=data.n_class\n",
    "    kSigVal,kSigVec=getKlargestSigVec(Lbar,top_k)\n",
    "    centroid=kmeans(kSigVec.astype(float),data.n_class)[0] #change kSigvec from complex64 to float\n",
    "    result=vq(kSigVec.astype(float),centroid)[0]\n",
    "\n",
    "    \n",
    "    perm = permutations(range(data.n_class)) \n",
    "    one_hot_result=one_hot(result,data.n_class)\n",
    "    acc_test=0\n",
    "    f1_test=0\n",
    "    auc_test=0\n",
    "    count=0\n",
    "    for i in perm: \n",
    "        count+=1\n",
    "        one_hot_i=one_hot(np.array(i))\n",
    "        perm_result=np.matmul(one_hot_result,one_hot_i)\n",
    "        labels = np.argmax(data.labels,axis=1)\n",
    "        pred_labels=np.argmax(perm_result,axis=1)\n",
    "        acc_test = max(metrics.accuracy_score(labels,pred_labels),acc_test)\n",
    "        f1_test=max(metrics.f1_score(labels, pred_labels,average='weighted'),f1_test)\n",
    "        auc_test=max(metrics.roc_auc_score(one_hot(labels), perm_result,multi_class='ovr',average='weighted'),auc_test)\n",
    "        if count%10000==0:\n",
    "            print(count)\n",
    "            print(acc_test,f1_test,auc_test)   \n",
    "    print(str(acc_test)+'\\t'+str(f1_test)+'\\t'+str(auc_test))  \n",
    "    try:\n",
    "        spec_norm=getKlargestSigVec(adj-Probability_matrix,2)[0]\n",
    "    except:\n",
    "        spec_norm=[]\n",
    "    return 0,acc_test,spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKlargestSigVec(Lbar,k):\n",
    "\t\"\"\"input\n",
    "\t\"matrix Lbar and k\n",
    "\t\"return\n",
    "\t\"k largest singular values and their corresponding eigen vectors\n",
    "\t\"\"\"\n",
    "\tlsigvec,sigval,rsigvec=linalg.svd(Lbar)\n",
    "\tdim=len(sigval)\n",
    " \n",
    "\t#find top k largest left sigval\n",
    "\tdictSigval=dict(zip(sigval,range(0,dim)))\n",
    "\tkSig=np.sort(sigval)[::-1][:k]#[0:k]\n",
    "\tix=[dictSigval[k] for k in kSig]\n",
    "\treturn sigval[ix],lsigvec[:,ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(l,classnum=1): #classnum fix some special case\n",
    "    one_hot_l=np.zeros((len(l),max(l.max()+1,classnum)))\n",
    "    for i in range(len(l)):\n",
    "        one_hot_l[i][l[i]]=1\n",
    "    return one_hot_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3200354609929078\t0.15898827304313726\t0.5013252489334223\n",
      "0.3200354609929078\t0.15898827304313726\t0.5013252489334223\n",
      "0.3200354609929078\t0.15898827304313726\t0.5013252489334223\n",
      "0.32092198581560283\t0.16074587507313426\t0.5019779904477827\n",
      "0.3200354609929078\t0.15898827304313726\t0.5013252489334223\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,5):\n",
    "    spectral(read_data(\"Brain\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynaernn(read_data(\"Brain\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50c3ad3fdabee9fdefd23e1a4e55e7732f1cc2e5176c2a0141ad64aed25ac9fb"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('original_repro': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
