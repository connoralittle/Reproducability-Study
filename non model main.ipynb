{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from utils import *\n",
    "\n",
    "from dynamicgem.embedding.dynAERNN  import DynAERNN \n",
    "import dgl  \n",
    "import scipy as sp\n",
    "import scipy.linalg as linalg\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "from scipy import stats \n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "from itertools import permutations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py): started\n",
      "  Building wheel for pytorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Installing collected packages: pytorch\n",
      "    Running setup.py install for pytorch: started\n",
      "    Running setup.py install for pytorch: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-f8gyxl3l\\\\pytorch_88cf76a7fd1047beace200ef44d0ef08\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-f8gyxl3l\\\\pytorch_88cf76a7fd1047beace200ef44d0ef08\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\conno\\AppData\\Local\\Temp\\pip-wheel-j61gc06h'\n",
      "       cwd: C:\\Users\\conno\\AppData\\Local\\Temp\\pip-install-f8gyxl3l\\pytorch_88cf76a7fd1047beace200ef44d0ef08\\\n",
      "  Complete output (5 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\conno\\AppData\\Local\\Temp\\pip-install-f8gyxl3l\\pytorch_88cf76a7fd1047beace200ef44d0ef08\\setup.py\", line 15, in <module>\n",
      "      raise Exception(message)\n",
      "  Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-f8gyxl3l\\\\pytorch_88cf76a7fd1047beace200ef44d0ef08\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-f8gyxl3l\\\\pytorch_88cf76a7fd1047beace200ef44d0ef08\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\conno\\AppData\\Local\\Temp\\pip-record-cfm1qg44\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\Include\\pytorch'\n",
      "         cwd: C:\\Users\\conno\\AppData\\Local\\Temp\\pip-install-f8gyxl3l\\pytorch_88cf76a7fd1047beace200ef44d0ef08\\\n",
      "    Complete output (5 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\conno\\AppData\\Local\\Temp\\pip-install-f8gyxl3l\\pytorch_88cf76a7fd1047beace200ef44d0ef08\\setup.py\", line 11, in <module>\n",
      "        raise Exception(message)\n",
      "    Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-f8gyxl3l\\\\pytorch_88cf76a7fd1047beace200ef44d0ef08\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Temp\\\\pip-install-f8gyxl3l\\\\pytorch_88cf76a7fd1047beace200ef44d0ef08\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\conno\\AppData\\Local\\Temp\\pip-record-cfm1qg44\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\Include\\pytorch' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(id: str): #DBLP3, DBLP5, Brain, Reddit, DBLPE\n",
    "    dataset_dict=dict()\n",
    "    dataset_dict[\"DBLP3\"]=\"Datasets/DBLP3.npz\"\n",
    "    dataset_dict[\"DBLP5\"]=\"Datasets/DBLP5.npz\"\n",
    "    dataset_dict[\"Brain\"]=\"Datasets/Brain.npz\"\n",
    "    dataset_dict[\"Reddit\"]=\"Datasets/reddit.npz\"\n",
    "    dataset_dict[\"DBLPE\"]=\"Datasets/DBLPE.npz\"\n",
    "\n",
    "    dataset = np.load(dataset_dict[id])\n",
    "    adjs = dataset[\"adjs\"] #(time, node, node)\n",
    "\n",
    "    #Remove nodes with no connections at any timestep\n",
    "    temporal_sum = np.add.reduce(adjs, axis=0, keepdims=False)\n",
    "    row_sum = np.add.reduce(temporal_sum, axis=0, keepdims=False)\n",
    "    non_zero_indices = np.flatnonzero(row_sum)\n",
    "    adjs = adjs[:,non_zero_indices,:]\n",
    "    adjs = adjs[:,:,non_zero_indices]\n",
    "\n",
    "    #DBLPE is a dynamic featureless graph\n",
    "    if id==\"DBLPE\":\n",
    "        labels = dataset[\"labels\"] #(nodes, time, class)\n",
    "\n",
    "        # labels = np.argmax(labels,axis=2)\n",
    "        labels=labels[non_zero_indices]\n",
    "        feats=np.zeros([adjs.shape[1], adjs.shape[0], adjs.shape[2]])\n",
    "\n",
    "        for i in range(feats.shape[1]):\n",
    "            feats[:,i,:]=np.eye(feats.shape[0])\n",
    "      \n",
    "    #All others are static feature-full graphs\n",
    "    else:\n",
    "        labels = dataset[\"labels\"] #(nodes, class)\n",
    "        feats = dataset[\"attmats\"] #(node, time, feat)\n",
    "\n",
    "        # labels = np.argmax(labels, axis=1)\n",
    "        labels = labels[non_zero_indices]\n",
    "        feats = feats[non_zero_indices]\n",
    "\n",
    "    #Other important variables\n",
    "    n_nodes = adjs.shape[1]\n",
    "    n_timesteps = adjs.shape[0]\n",
    "    n_class = int(labels.shape[1])\n",
    "    n_feat = feats.shape[2]\n",
    "\n",
    "    #Train Val Test split\n",
    "    nodes_id = list(range(n_nodes))\n",
    "    random.shuffle(nodes_id)\n",
    "    idx_train = nodes_id[:(7*n_nodes)//10]\n",
    "    idx_train = [True if i in idx_train else False for i in list(range(n_nodes))]\n",
    "    idx_val = nodes_id[(7*n_nodes)//10: (9*n_nodes)//10]\n",
    "    idx_val = [True if i in idx_val else False for i in list(range(n_nodes))]\n",
    "    idx_test = nodes_id[(9*n_nodes)//10: n_nodes]\n",
    "    idx_test = [True if i in idx_test else False for i in list(range(n_nodes))]\n",
    "\n",
    "    return STG_Dataset(np.array(adjs),\n",
    "                        np.array(adjs),\n",
    "                        np.array(feats), \n",
    "                        np.array(feats), \n",
    "                        np.array(labels), \n",
    "                        np.array(labels), \n",
    "                        n_nodes, n_timesteps, n_class, n_feat, \n",
    "                        np.array(idx_train),\n",
    "                        np.array(idx_val),\n",
    "                        np.array(idx_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynaernn(data):\n",
    "    length=data.n_timestamps\n",
    "    lookup=length-2\n",
    "\n",
    "    dim_emb  = data.n_class\n",
    "          \n",
    "    tf.device('/gpu:0')\n",
    "\n",
    "    embedding = DynAERNN(d   = dim_emb,\n",
    "        beta           = 5,\n",
    "        n_prev_graphs  = lookup,\n",
    "        nu1            = 1e-6,\n",
    "        nu2            = 1e-6,\n",
    "        n_aeunits      = [50, 30],\n",
    "        n_lstmunits    = [50,dim_emb],\n",
    "        rho            = 0.3,\n",
    "        n_iter         = 2,\n",
    "        xeta           = 1e-3,\n",
    "        n_batch        = 10,\n",
    "        modelfile      = ['./intermediate/enc_model_dynAERNN.json', \n",
    "                            './intermediate/dec_model_dynAERNN.json'],\n",
    "        weightfile     = ['./intermediate/enc_weights_dynAERNN.hdf5', \n",
    "                            './intermediate/dec_weights_dynAERNN.hdf5'],\n",
    "        savefilesuffix = \"testing\")\n",
    "    embs = []\n",
    "\n",
    "    graphs     = [nx.Graph(data.adjs[l,:,:]) for l in range(length)]\n",
    "    for temp_var in range(lookup, length):\n",
    "                    emb, _ = embedding.learn_embeddings(graphs[:temp_var])\n",
    "                    embs.append(emb)\n",
    "    centroid=kmeans(embs[-1],data.n_class)[0] #change kSigvec from complex64 to float\n",
    "    result=vq(embs[-1],centroid)[0]\n",
    "\n",
    "\n",
    "\n",
    "    perm = permutations(range(data.n_class)) \n",
    "    one_hot_result=one_hot(result,data.n_class)\n",
    "    acc_test=0\n",
    "    f1_test=0\n",
    "    auc_test=0\n",
    "    count=0\n",
    "    for i in perm: \n",
    "        count+=1\n",
    "        one_hot_i=one_hot(np.array(i))\n",
    "        perm_result=np.matmul(one_hot_result,one_hot_i)\n",
    "        labels = np.argmax(data.labels,axis=1)\n",
    "        pred_labels=np.argmax(perm_result,axis=1)\n",
    "        acc_test = max(metrics.accuracy_score(labels,pred_labels),acc_test)\n",
    "        f1_test=max(metrics.f1_score(labels, pred_labels,average='weighted'),f1_test)\n",
    "        auc_test=max(metrics.roc_auc_score(one_hot(labels), perm_result,multi_class='ovr',average='weighted'),auc_test)\n",
    "        if count%10000==0:\n",
    "            print(count)\n",
    "            print(acc_test,f1_test,auc_test)   \n",
    "    print(str(acc_test)+'\\t'+str(f1_test)+'\\t'+str(auc_test))  \n",
    "    try:\n",
    "        spec_norm=getKlargestSigVec(adj-Probability_matrix,2)[0]\n",
    "    except:\n",
    "        spec_norm=[]\n",
    "    return 0,acc_test,spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral(data):\n",
    "    adj = np.add.reduce(data.adjs_timestep, axis=0, keepdims=False, dtype=np.float32)\n",
    "\n",
    "    #normalize the adj matrix\n",
    "    adj += np.eye(adj.shape[0], dtype=np.float32)\n",
    "    d = np.add.reduce(adj, axis=1)\n",
    "    normalizing_matrix = np.zeros((adj.shape[0], adj.shape[0]))\n",
    "    normalizing_matrix[range(len(normalizing_matrix)), range(len(normalizing_matrix))] = d**(-0.5)\n",
    "    adj = np.matmul(normalizing_matrix,adj)\n",
    "    adj=np.matmul(np.matmul(normalizing_matrix,adj), normalizing_matrix)\n",
    "\n",
    "    Lbar=np.array(adj)  #no normalizaton\n",
    "    top_k=data.n_class\n",
    "    kSigVal,kSigVec=getKlargestSigVec(Lbar,top_k)\n",
    "    centroid=kmeans(kSigVec.astype(float),data.n_class)[0] #change kSigvec from complex64 to float\n",
    "    result=vq(kSigVec.astype(float),centroid)[0]\n",
    "\n",
    "    \n",
    "    perm = permutations(range(data.n_class)) \n",
    "    one_hot_result=one_hot(result,data.n_class)\n",
    "    acc_test=0\n",
    "    f1_test=0\n",
    "    auc_test=0\n",
    "    count=0\n",
    "    for i in perm: \n",
    "        count+=1\n",
    "        one_hot_i=one_hot(np.array(i))\n",
    "        perm_result=np.matmul(one_hot_result,one_hot_i)\n",
    "        labels = np.argmax(data.labels,axis=1)\n",
    "        pred_labels=np.argmax(perm_result,axis=1)\n",
    "        acc_test = max(metrics.accuracy_score(labels,pred_labels),acc_test)\n",
    "        f1_test=max(metrics.f1_score(labels, pred_labels,average='weighted'),f1_test)\n",
    "        auc_test=max(metrics.roc_auc_score(one_hot(labels), perm_result,multi_class='ovr',average='weighted'),auc_test)\n",
    "        if count%10000==0:\n",
    "            print(count)\n",
    "            print(acc_test,f1_test,auc_test)   \n",
    "    print(str(acc_test)+'\\t'+str(f1_test)+'\\t'+str(auc_test))  \n",
    "    try:\n",
    "        spec_norm=getKlargestSigVec(adj-Probability_matrix,2)[0]\n",
    "    except:\n",
    "        spec_norm=[]\n",
    "    return 0,acc_test,spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKlargestSigVec(Lbar,k):\n",
    "\t\"\"\"input\n",
    "\t\"matrix Lbar and k\n",
    "\t\"return\n",
    "\t\"k largest singular values and their corresponding eigen vectors\n",
    "\t\"\"\"\n",
    "\tlsigvec,sigval,rsigvec=linalg.svd(Lbar)\n",
    "\tdim=len(sigval)\n",
    " \n",
    "\t#find top k largest left sigval\n",
    "\tdictSigval=dict(zip(sigval,range(0,dim)))\n",
    "\tkSig=np.sort(sigval)[::-1][:k]#[0:k]\n",
    "\tix=[dictSigval[k] for k in kSig]\n",
    "\treturn sigval[ix],lsigvec[:,ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(l,classnum=1): #classnum fix some special case\n",
    "    one_hot_l=np.zeros((len(l),max(l.max()+1,classnum)))\n",
    "    for i in range(len(l)):\n",
    "        one_hot_l[i][l[i]]=1\n",
    "    return one_hot_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6732217573221757\t0.541742339350528\t0.5\n",
      "0.6732217573221757\t0.541742339350528\t0.5\n",
      "0.6723849372384937\t0.5413396867734483\t0.5004935834155972\n",
      "0.6723849372384937\t0.5413396867734483\t0.5004935834155972\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,10):\n",
    "    spectral(read_data(\"DBLP5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\embedding\\dynAERNN.py:124: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\embedding\\dynAERNN.py:134: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:491: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y[i])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\keras\\activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:491: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y[i])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:493: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y[K - 1])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:495: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  encoder = Model(input=x, output=y[K])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:533: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y_hat[i + 1])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:533: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y_hat[i + 1])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:535: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2390, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y_hat[1])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:540: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  decoder = Model(input=y, output=x_hat)\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:885: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n",
      "  autoencoder = Model(input=x_in, output=[x_hat, y])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\embedding\\dynAERNN.py:205: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"su...)`\n",
      "  self._model = Model(input=[x_in, x_pred], output=x_diff)\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\embedding\\dynAERNN.py:225: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  verbose=1\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\embedding\\dynAERNN.py:225: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., verbose=1, steps_per_epoch=1912, epochs=2)`\n",
      "  verbose=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/2\n",
      "1912/1912 [==============================] - 55s 29ms/step - loss: 5.5581e-04\n",
      "Epoch 2/2\n",
      "1912/1912 [==============================] - 45s 24ms/step - loss: 1.3365e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:491: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y[i])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\keras\\activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:491: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y[i])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:493: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y[K - 1])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:495: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  encoder = Model(input=x, output=y[K])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:533: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y_hat[i + 1])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:533: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y_hat[i + 1])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:535: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2390, activation=<keras.lay..., kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=Reg.l1_l2(l1=nu1, l2=nu2))(y_hat[1])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:540: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  decoder = Model(input=y, output=x_hat)\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\utils\\dnn_utils.py:885: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n",
      "  autoencoder = Model(input=x_in, output=[x_hat, y])\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\embedding\\dynAERNN.py:205: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"su...)`\n",
      "  self._model = Model(input=[x_in, x_pred], output=x_diff)\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\embedding\\dynAERNN.py:225: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  verbose=1\n",
      "C:\\Users\\conno\\anaconda3\\envs\\dynamicgem_env\\lib\\site-packages\\dynamicgem\\embedding\\dynAERNN.py:225: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., verbose=1, steps_per_epoch=1912, epochs=2)`\n",
      "  verbose=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1912/1912 [==============================] - 52s 27ms/step - loss: 45.3133\n",
      "Epoch 2/2\n",
      "1912/1912 [==============================] - 46s 24ms/step - loss: 36.6630\n",
      "0.3916317991631799\t0.4368440438171778\t0.5110646902119681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.3916317991631799, [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynaernn(read_data(\"DBLP5\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50c3ad3fdabee9fdefd23e1a4e55e7732f1cc2e5176c2a0141ad64aed25ac9fb"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('original_repro': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
